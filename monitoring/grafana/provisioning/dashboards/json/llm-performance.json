{
  "annotations": {
    "list": []
  },
  "editable": false,
  "fiscalYearStartMonth": 0,
  "gnetId": null,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "legend": {
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "targets": [
        {
          "expr": "sum(rate(twiga_llm_calls_total[5m])) by (provider, model, outcome)",
          "legendFormat": "{{provider}} | {{model}} | {{outcome}}",
          "refId": "A"
        }
      ],
      "title": "LLM Call Rate by Outcome",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 2,
      "options": {
        "legend": {
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.5, sum(rate(twiga_llm_latency_seconds_bucket[5m])) by (provider, model, le))",
          "legendFormat": "{{provider}} | {{model}} | p50",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.9, sum(rate(twiga_llm_latency_seconds_bucket[5m])) by (provider, model, le))",
          "legendFormat": "{{provider}} | {{model}} | p90",
          "refId": "B"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(twiga_llm_latency_seconds_bucket[5m])) by (provider, model, le))",
          "legendFormat": "{{provider}} | {{model}} | p99",
          "refId": "C"
        }
      ],
      "title": "LLM Latency Quantiles",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "palette-classic"
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 24,
        "x": 0,
        "y": 8
      },
      "id": 3,
      "options": {
        "legend": {
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "targets": [
        {
          "expr": "sum by (feature) (increase(twiga_messages_generated_total[1h]))",
          "legendFormat": "{{feature}}",
          "refId": "A"
        }
      ],
      "title": "Messages Generated (last hour)",
      "type": "timeseries"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": [
    "llm",
    "twiga"
  ],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "title": "LLM Performance",
  "uid": "llm-performance",
  "version": 1,
  "weekStart": ""
}
